#!/usr/bin/env python

from __future__ import division

from Pegasus.DAX3 import *
import sys
import math
import os
import re
import subprocess
import ConfigParser

base_dir = os.getcwd()

run_id = sys.argv[1]
run_dir = sys.argv[2]    
job_start = int(sys.argv[3])
job_end = int(sys.argv[4])

# Create a abstract dag
dax = ADAG("macsswig_simsaj")

# email notificiations for when the state of the workflow changes
dax.invoke('all',  base_dir + "/tools/email-notify")

# Add executables to the DAX-level replica catalog
for exe_name in os.listdir("./wrappers/"):
    exe = Executable(name=exe_name, arch="x86_64", installed=False)
    exe.addPFN(PFN("file://" + base_dir + "/wrappers/" + exe_name, "local"))
    dax.addExecutable(exe)

# common inputs

model_file = File("model.tar.gz")
model_file.addPFN(PFN("file://" + base_dir + "/model.tar.gz", "local"))
dax.addFile(model_file)

input_file = File("ftDNA_hg18_auto_all_uniqSNPS_rmbadsites_pruned_chr1.bed")
input_file.addPFN(PFN("file://" + base_dir + "/../ftDNA_hg18_auto_all_uniqSNPS_rmbadsites_pruned_chr1.bed", "local"))
dax.addFile(input_file)

prepare_jobs = []
input_id = 0
for job_id in range(job_start, job_end + 1):
    # the real work
    sim_job = Job(name="run-sim.sh")
    sim_job.uses(model_file, link=Link.INPUT)
    sim_job.uses(input_file, link=Link.INPUT)
    sim_job.addArguments(str(job_id), input_file, "full")

    # output files
    f1 = File("outputs-" + str(job_id) + ".tar.gz")
    sim_job.uses(f1, link=Link.OUTPUT)

    # set a priority to the jobs run in about the expected order
    priority = 10000000 - job_id
    sim_job.addProfile(Profile(Namespace.CONDOR, "priority", priority))

    dax.addJob(sim_job)
    

# Write the DAX to stdout
f = open("dax.xml", "w")
dax.writeXML(f)
f.close()


